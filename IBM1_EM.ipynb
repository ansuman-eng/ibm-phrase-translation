{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the file name of the parallel corpus\n",
      "data3.json\n"
     ]
    }
   ],
   "source": [
    "print(\"Give the file name of the parallel corpus\")\n",
    "file_name=raw_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data and make proper sentences\n",
    "#fr=[], will contain a list of French sentences\n",
    "#en=[], will contain a list of English sentences\n",
    "\n",
    "json_data=open(file_name).read()\n",
    "data = json.loads(json_data)\n",
    "#print(type(data))\n",
    "fr=[]\n",
    "en=[]\n",
    "for i in data:\n",
    "    fr.append(i[\"fr\"])\n",
    "    en.append(i[\"en\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la fille est en france\n",
      "paris est une ville en france\n",
      "la fille est belle\n",
      "paris est une belle ville\n",
      "la fille est a la eglise\n",
      "une eglise est en paris\n",
      "la eglise est belle\n",
      "la france a une belle eglise\n"
     ]
    }
   ],
   "source": [
    "#Each sentence is tokenized into a list for ease of processing\n",
    "for i in range(len(fr)):\n",
    "    print(fr[i])\n",
    "    fr[i]=str(fr[i])\n",
    "    en[i]=str(en[i])\n",
    "\n",
    "for i in range(len(fr)):\n",
    "    fr[i]=fr[i].split(' ')\n",
    "    en[i]=en[i].split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distinct_en will contain a list of distinct English words\n",
    "#distinct_fr will contain a list of distinct French words\n",
    "\n",
    "distinct_en=[]\n",
    "distinct_fr=[]\n",
    "\n",
    "for e in en:\n",
    "    for word in e:\n",
    "        if(word not in distinct_en):\n",
    "            distinct_en.append(word)\n",
    "\n",
    "for f in fr:\n",
    "    for word in f:\n",
    "        if(word not in distinct_fr):\n",
    "            distinct_fr.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'girl', 'is', 'in', 'france', 'paris', 'a', 'city', 'beautiful', 'church', 'has']\n",
      "['la', 'fille', 'est', 'en', 'france', 'paris', 'une', 'ville', 'belle', 'a', 'eglise']\n"
     ]
    }
   ],
   "source": [
    "#Debug\n",
    "print(distinct_en)\n",
    "print(distinct_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('a', 'a'), 0.09090909090909091)\n",
      "(('a', 'belle'), 0.09090909090909091)\n",
      "(('a', 'eglise'), 0.09090909090909091)\n",
      "(('a', 'en'), 0.09090909090909091)\n",
      "(('a', 'est'), 0.09090909090909091)\n",
      "(('a', 'fille'), 0.09090909090909091)\n",
      "(('a', 'france'), 0.09090909090909091)\n",
      "(('a', 'la'), 0.09090909090909091)\n",
      "(('a', 'paris'), 0.09090909090909091)\n",
      "(('a', 'une'), 0.09090909090909091)\n",
      "(('a', 'ville'), 0.09090909090909091)\n",
      "(('beautiful', 'a'), 0.09090909090909091)\n",
      "(('beautiful', 'belle'), 0.09090909090909091)\n",
      "(('beautiful', 'eglise'), 0.09090909090909091)\n",
      "(('beautiful', 'en'), 0.09090909090909091)\n",
      "(('beautiful', 'est'), 0.09090909090909091)\n",
      "(('beautiful', 'fille'), 0.09090909090909091)\n",
      "(('beautiful', 'france'), 0.09090909090909091)\n",
      "(('beautiful', 'la'), 0.09090909090909091)\n",
      "(('beautiful', 'paris'), 0.09090909090909091)\n",
      "(('beautiful', 'une'), 0.09090909090909091)\n",
      "(('beautiful', 'ville'), 0.09090909090909091)\n",
      "(('church', 'a'), 0.09090909090909091)\n",
      "(('church', 'belle'), 0.09090909090909091)\n",
      "(('church', 'eglise'), 0.09090909090909091)\n",
      "(('church', 'en'), 0.09090909090909091)\n",
      "(('church', 'est'), 0.09090909090909091)\n",
      "(('church', 'fille'), 0.09090909090909091)\n",
      "(('church', 'france'), 0.09090909090909091)\n",
      "(('church', 'la'), 0.09090909090909091)\n",
      "(('church', 'paris'), 0.09090909090909091)\n",
      "(('church', 'une'), 0.09090909090909091)\n",
      "(('church', 'ville'), 0.09090909090909091)\n",
      "(('city', 'a'), 0.09090909090909091)\n",
      "(('city', 'belle'), 0.09090909090909091)\n",
      "(('city', 'eglise'), 0.09090909090909091)\n",
      "(('city', 'en'), 0.09090909090909091)\n",
      "(('city', 'est'), 0.09090909090909091)\n",
      "(('city', 'fille'), 0.09090909090909091)\n",
      "(('city', 'france'), 0.09090909090909091)\n",
      "(('city', 'la'), 0.09090909090909091)\n",
      "(('city', 'paris'), 0.09090909090909091)\n",
      "(('city', 'une'), 0.09090909090909091)\n",
      "(('city', 'ville'), 0.09090909090909091)\n",
      "(('france', 'a'), 0.09090909090909091)\n",
      "(('france', 'belle'), 0.09090909090909091)\n",
      "(('france', 'eglise'), 0.09090909090909091)\n",
      "(('france', 'en'), 0.09090909090909091)\n",
      "(('france', 'est'), 0.09090909090909091)\n",
      "(('france', 'fille'), 0.09090909090909091)\n",
      "(('france', 'france'), 0.09090909090909091)\n",
      "(('france', 'la'), 0.09090909090909091)\n",
      "(('france', 'paris'), 0.09090909090909091)\n",
      "(('france', 'une'), 0.09090909090909091)\n",
      "(('france', 'ville'), 0.09090909090909091)\n",
      "(('girl', 'a'), 0.09090909090909091)\n",
      "(('girl', 'belle'), 0.09090909090909091)\n",
      "(('girl', 'eglise'), 0.09090909090909091)\n",
      "(('girl', 'en'), 0.09090909090909091)\n",
      "(('girl', 'est'), 0.09090909090909091)\n",
      "(('girl', 'fille'), 0.09090909090909091)\n",
      "(('girl', 'france'), 0.09090909090909091)\n",
      "(('girl', 'la'), 0.09090909090909091)\n",
      "(('girl', 'paris'), 0.09090909090909091)\n",
      "(('girl', 'une'), 0.09090909090909091)\n",
      "(('girl', 'ville'), 0.09090909090909091)\n",
      "(('has', 'a'), 0.09090909090909091)\n",
      "(('has', 'belle'), 0.09090909090909091)\n",
      "(('has', 'eglise'), 0.09090909090909091)\n",
      "(('has', 'en'), 0.09090909090909091)\n",
      "(('has', 'est'), 0.09090909090909091)\n",
      "(('has', 'fille'), 0.09090909090909091)\n",
      "(('has', 'france'), 0.09090909090909091)\n",
      "(('has', 'la'), 0.09090909090909091)\n",
      "(('has', 'paris'), 0.09090909090909091)\n",
      "(('has', 'une'), 0.09090909090909091)\n",
      "(('has', 'ville'), 0.09090909090909091)\n",
      "(('in', 'a'), 0.09090909090909091)\n",
      "(('in', 'belle'), 0.09090909090909091)\n",
      "(('in', 'eglise'), 0.09090909090909091)\n",
      "(('in', 'en'), 0.09090909090909091)\n",
      "(('in', 'est'), 0.09090909090909091)\n",
      "(('in', 'fille'), 0.09090909090909091)\n",
      "(('in', 'france'), 0.09090909090909091)\n",
      "(('in', 'la'), 0.09090909090909091)\n",
      "(('in', 'paris'), 0.09090909090909091)\n",
      "(('in', 'une'), 0.09090909090909091)\n",
      "(('in', 'ville'), 0.09090909090909091)\n",
      "(('is', 'a'), 0.09090909090909091)\n",
      "(('is', 'belle'), 0.09090909090909091)\n",
      "(('is', 'eglise'), 0.09090909090909091)\n",
      "(('is', 'en'), 0.09090909090909091)\n",
      "(('is', 'est'), 0.09090909090909091)\n",
      "(('is', 'fille'), 0.09090909090909091)\n",
      "(('is', 'france'), 0.09090909090909091)\n",
      "(('is', 'la'), 0.09090909090909091)\n",
      "(('is', 'paris'), 0.09090909090909091)\n",
      "(('is', 'une'), 0.09090909090909091)\n",
      "(('is', 'ville'), 0.09090909090909091)\n",
      "(('paris', 'a'), 0.09090909090909091)\n",
      "(('paris', 'belle'), 0.09090909090909091)\n",
      "(('paris', 'eglise'), 0.09090909090909091)\n",
      "(('paris', 'en'), 0.09090909090909091)\n",
      "(('paris', 'est'), 0.09090909090909091)\n",
      "(('paris', 'fille'), 0.09090909090909091)\n",
      "(('paris', 'france'), 0.09090909090909091)\n",
      "(('paris', 'la'), 0.09090909090909091)\n",
      "(('paris', 'paris'), 0.09090909090909091)\n",
      "(('paris', 'une'), 0.09090909090909091)\n",
      "(('paris', 'ville'), 0.09090909090909091)\n",
      "(('the', 'a'), 0.09090909090909091)\n",
      "(('the', 'belle'), 0.09090909090909091)\n",
      "(('the', 'eglise'), 0.09090909090909091)\n",
      "(('the', 'en'), 0.09090909090909091)\n",
      "(('the', 'est'), 0.09090909090909091)\n",
      "(('the', 'fille'), 0.09090909090909091)\n",
      "(('the', 'france'), 0.09090909090909091)\n",
      "(('the', 'la'), 0.09090909090909091)\n",
      "(('the', 'paris'), 0.09090909090909091)\n",
      "(('the', 'une'), 0.09090909090909091)\n",
      "(('the', 'ville'), 0.09090909090909091)\n"
     ]
    }
   ],
   "source": [
    "#t_val is a dictionary where each key is of the form (english_word, french_word) and the corresponding value\n",
    "#is t(english_word|french_word)\n",
    "#We have to initialize them uniformly, so t(english_word|french_word) for each pair becomes 1/(number of distinct_english_words)\n",
    "\n",
    "t_val={}\n",
    "for f_word in distinct_fr:\n",
    "    for e_word in distinct_en:\n",
    "            t_val[(e_word,f_word)]=1.0/(len(distinct_en))\n",
    "            \n",
    "#Pairs and initial probabilities\n",
    "for key,val in sorted(t_val.items()):\n",
    "    print(key,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235\n"
     ]
    }
   ],
   "source": [
    "#TRAINING MY MODEL\n",
    "#We run the model for 100 iterations or until it converges, whichever is earlier\n",
    "#epoch = number of iterations\n",
    "\n",
    "epoch=10000\n",
    "while(epoch!=0):\n",
    "    \n",
    "    total_difference=0.0\n",
    "    #counts of English word given a French Word\n",
    "    count={}\n",
    "    \n",
    "    total={}\n",
    "    \n",
    "    for f_word in distinct_fr:\n",
    "        for e_word in distinct_en:\n",
    "            count[(e_word,f_word)]=0\n",
    "    for f_word in distinct_fr:\n",
    "        total[f_word]=0\n",
    "    \n",
    "    for i in range(len(fr)):\n",
    "        f=fr[i]\n",
    "        e=en[i]\n",
    "        #normalization for an English word weighed by the prior translation probabilities\n",
    "        s_total={}\n",
    "        #stores the sum of translation probabilities corresponding to a French word in the sentence, normalized\n",
    "        for e_word in e:\n",
    "            s_total[e_word]=0\n",
    "            for f_word in f:\n",
    "                s_total[e_word]+=(t_val[(e_word,f_word)])\n",
    "            #endfor\n",
    "        #endfor\n",
    "\n",
    "        for e_word in e:\n",
    "            for f_word in f:\n",
    "                count[(e_word,f_word)]+=(t_val[(e_word,f_word)]/s_total[e_word])\n",
    "                total[f_word]+=(t_val[(e_word,f_word)]/s_total[e_word])\n",
    "                #print(f_word, total[f_word])\n",
    "            #endfor\n",
    "        #endfor\n",
    "    #endfor_twice\n",
    "    #print(total)\n",
    "    \n",
    "    for f_word in distinct_fr:\n",
    "        for e_word in distinct_en:\n",
    "            total_difference+=abs((t_val[(e_word,f_word)]-(count[(e_word,f_word)]/total[f_word])))\n",
    "            t_val[(e_word,f_word)]=(count[(e_word,f_word)]/total[f_word])\n",
    "        #endfor\n",
    "    #endfor\n",
    "    \n",
    "    \n",
    "    #print(\"Total displacement : \", total_difference)\n",
    "    if(total_difference < 0.0001):\n",
    "        break\n",
    "    epoch-=1\n",
    "print(10000-epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (1, 1), (2, 2), (3, 3), (4, 4)]\n",
      "[(0, 0), (1, 1), (2, 2), (3, 3), (4, 4), (5, 5)]\n",
      "[(0, 0), (1, 1), (2, 2), (3, 3)]\n",
      "[(0, 0), (1, 1), (2, 2), (3, 3), (4, 4)]\n",
      "[(0, 0), (1, 1), (2, 2), (3, 3), (4, 5)]\n",
      "[(0, 0), (1, 1), (2, 2), (3, 3), (4, 4)]\n",
      "[(0, 0), (1, 1), (2, 2), (3, 3)]\n",
      "[(0, 1), (1, 2), (2, 3), (3, 4), (4, 5)]\n"
     ]
    }
   ],
   "source": [
    "#ALIGNMENTS OF MY MODEL\n",
    "for i in range(len(fr)):\n",
    "    f=np.array(fr[i])#French sentence in the pair\n",
    "    e=np.array(en[i])#English sentence in the pair\n",
    "    #print(e)\n",
    "    #print(f)\n",
    "    align=[]\n",
    "    #For every word in the English sentence, check which word in the French sentence has the maximum\n",
    "    #probability of producing the former and align them\n",
    "    for e_i in range(len(e)):\n",
    "        max_sim=-1\n",
    "        max_f=-1\n",
    "        for f_i in range(len(f)):\n",
    "            if(t_val[(e[e_i],f[f_i])]>max_sim):\n",
    "                max_f=f_i\n",
    "                max_sim=t_val[(e[e_i],f[f_i])]\n",
    "        align.append((e_i,max_f))\n",
    "    print(align)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING IBM MODEL 1\n",
    "from collections import defaultdict\n",
    "from nltk.translate import AlignedSent\n",
    "from nltk.translate import Alignment\n",
    "from nltk.translate import IBMModel,IBMModel1, IBMModel2\n",
    "from nltk.translate.ibm_model import Counts\n",
    "#bitext will have the parallel corpus\n",
    "bitext=[]\n",
    "for i in range(len(fr)):\n",
    "    bitext.append(AlignedSent(en[i],fr[i]))\n",
    "#Training for 100 iterations\n",
    "ibm1 = IBMModel1(bitext,1000)\n",
    "#trans_dict will contain the translation probabilities for each distinct pair of words\n",
    "#pair being of the form (english_word,french_word)\n",
    "trans_dict=ibm1.translation_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-0 1-1 2-2 3-3 4-4\n",
      "0-0 1-1 2-2 3-3 4-4 5-5\n",
      "0-0 1-1 2-2 3-3\n",
      "0-0 1-1 2-2 3-3 4-4\n",
      "0-4 1-1 2-2 3-3 4-5\n",
      "0-0 1-1 2-2 3-3 4-4\n",
      "0-0 1-1 2-2 3-3\n",
      "0-1 1-2 2-3 3-4 4-5\n"
     ]
    }
   ],
   "source": [
    "#ALIGNMENTS OF IBM MODEL 1\n",
    "for i in range(len(fr)):\n",
    "    test_sentence=bitext[i]\n",
    "    align_ibm=test_sentence.alignment\n",
    "    #print(test_sentence)\n",
    "    print(align_ibm)\n",
    "    #print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING IBM MODEL 2\n",
    "#bitext_2 will have the parallel corpus\n",
    "\n",
    "bitext_2=[]\n",
    "for i in range(len(fr)):\n",
    "    bitext_2.append(AlignedSent(en[i],fr[i]))\n",
    "    \n",
    "#Training for 100 iterations    \n",
    "ibm2 = IBMModel2(bitext_2,1000)\n",
    "#trans_dict_2 will contain the translation probabilities for each distinct pair of words\n",
    "#pair being of the form (english_word,french_word)\n",
    "trans_dict_2=ibm2.translation_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-0 1-1 2-2 3-3 4-4\n",
      "0-0 1-1 2-2 3-3 4-4 5-5\n",
      "0-0 1-1 2-2 3-3\n",
      "0-0 1-1 2-2 3-3 4-4\n",
      "0-4 1-1 2-2 3-3 4-5\n",
      "0-0 1-1 2-2 3-3 4-4\n",
      "0-0 1-1 2-2 3-3\n",
      "0-1 1-2 2-3 3-4 4-5\n"
     ]
    }
   ],
   "source": [
    "#ALIGNMENTS OF IBM MODEL 2\n",
    "for i in range(len(fr)):\n",
    "    test_sentence=bitext_2[i]\n",
    "    align_ibm2=test_sentence.alignment\n",
    "    #print(test_sentence)\n",
    "    print(align_ibm2)\n",
    "    #print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the girl is in france\n",
      "la fille est en france\n",
      " \n",
      "paris is a city in france\n",
      "paris est une ville en france\n",
      " \n",
      "the girl is beautiful\n",
      "la fille est belle\n",
      " \n",
      "paris is a beautiful city\n",
      "paris est une belle ville\n",
      " \n",
      "the girl is in church\n",
      "la fille est a la eglise\n",
      " \n",
      "a church is in paris\n",
      "une eglise est en paris\n",
      " \n",
      "the church is beautiful\n",
      "la eglise est belle\n",
      " \n",
      "france has a beautiful church\n",
      "la france a une belle eglise\n",
      " \n"
     ]
    }
   ],
   "source": [
    "'''Here then notion of source and target gets reversed\n",
    "The source is basically the source of alignment - which is actually the target for IBM1 i.e English'''\n",
    "from nltk.translate.phrase_based import phrase_extraction\n",
    "count_fr_phrase={}\n",
    "count_en_fr_phrase={}\n",
    "for i in range(len(fr)):\n",
    "    \n",
    "    test_sentence = bitext[i]\n",
    "    #print(test_sentence)\n",
    "    align_ibm=test_sentence.alignment\n",
    "    \n",
    "    \n",
    "    f=np.array(fr[i])\n",
    "    e=np.array(en[i])\n",
    "    align=[]\n",
    "    #For each sentence pair, make the alignment\n",
    "    for e_i in range(len(e)):\n",
    "        max_sim=-1\n",
    "        max_f=-1\n",
    "        for f_i in range(len(f)):\n",
    "            if(t_val[(e[e_i],f[f_i])]>max_sim):\n",
    "                max_f=f_i\n",
    "                max_sim=t_val[(e[e_i],f[f_i])]\n",
    "        align.append((e_i,max_f))\n",
    "\n",
    "    #Construct the source and target texts\n",
    "    srctext=\"\"\n",
    "    trgtext=\"\"\n",
    "    for e_word in e:\n",
    "        srctext+=e_word\n",
    "        srctext+=' '\n",
    "    for f_word in f:\n",
    "        trgtext+=f_word\n",
    "        trgtext+=' '\n",
    "    srctext=srctext[:-1]\n",
    "    trgtext=trgtext[:-1]\n",
    "    print(srctext)\n",
    "    print(trgtext)\n",
    "    \n",
    "    #Obtain phrase tuples from phrase_extraction module\n",
    "    phrases = phrase_extraction(srctext, trgtext, align_ibm)\n",
    "    for phrase in sorted(phrases):\n",
    "        en_phrase=phrase[2]#English phrase\n",
    "        fr_phrase=phrase[3]#French phrase\n",
    "        #Increment count of the French phrase \n",
    "        if(fr_phrase not in count_fr_phrase):\n",
    "            count_fr_phrase[fr_phrase]=1\n",
    "        else:\n",
    "            count_fr_phrase[fr_phrase]+=1\n",
    "        \n",
    "        #Increment count of the pair of English phrase, French phrase\n",
    "        if((en_phrase,fr_phrase) not in count_en_fr_phrase):            \n",
    "            count_en_fr_phrase[(en_phrase,fr_phrase)]=1\n",
    "        else:            \n",
    "            count_en_fr_phrase[(en_phrase,fr_phrase)]+=1    \n",
    "                \n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, ('the girl is in france', 'la fille est en france'))\n",
      "(1.0, ('the girl is in church', 'la fille est a la eglise'))\n",
      "(1.0, ('the girl is in church', 'fille est a la eglise'))\n",
      "(1.0, ('the girl is in', 'la fille est en'))\n",
      "(1.0, ('the girl is in', 'la fille est a la'))\n",
      "(1.0, ('the girl is in', 'fille est a la'))\n",
      "(1.0, ('the girl is beautiful', 'la fille est belle'))\n",
      "(1.0, ('the church is beautiful', 'la eglise est belle'))\n",
      "(1.0, ('the church is', 'la eglise est'))\n",
      "(1.0, ('the church', 'la eglise'))\n",
      "(1.0, ('the', 'la'))\n",
      "(1.0, ('paris is a city in france', 'paris est une ville en france'))\n",
      "(1.0, ('paris is a city in', 'paris est une ville en'))\n",
      "(1.0, ('paris is a city', 'paris est une ville'))\n",
      "(1.0, ('paris is a beautiful city', 'paris est une belle ville'))\n",
      "(1.0, ('paris is a beautiful', 'paris est une belle'))\n",
      "(1.0, ('paris is a', 'paris est une'))\n",
      "(1.0, ('paris is', 'paris est'))\n",
      "(1.0, ('paris', 'paris'))\n",
      "(1.0, ('is in paris', 'est en paris'))\n",
      "(1.0, ('is in france', 'est en france'))\n",
      "(1.0, ('is in', 'est en'))\n",
      "(1.0, ('is in', 'est a'))\n",
      "(1.0, ('is beautiful', 'est belle'))\n",
      "(1.0, ('is a city in france', 'est une ville en france'))\n",
      "(1.0, ('is a city in', 'est une ville en'))\n",
      "(1.0, ('is a city', 'est une ville'))\n",
      "(1.0, ('is a beautiful city', 'est une belle ville'))\n",
      "(1.0, ('is a beautiful', 'est une belle'))\n",
      "(1.0, ('is a', 'est une'))\n",
      "(1.0, ('is', 'est'))\n",
      "(1.0, ('in paris', 'en paris'))\n",
      "(1.0, ('in france', 'en france'))\n",
      "(1.0, ('in', 'en'))\n",
      "(1.0, ('has a beautiful church', 'a une belle eglise'))\n",
      "(1.0, ('has a beautiful', 'a une belle'))\n",
      "(1.0, ('has a', 'a une'))\n",
      "(1.0, ('girl is in france', 'fille est en france'))\n",
      "(1.0, ('girl is in', 'la fille est a'))\n",
      "(1.0, ('girl is in', 'fille est en'))\n",
      "(1.0, ('girl is in', 'fille est a'))\n",
      "(1.0, ('girl is beautiful', 'fille est belle'))\n",
      "(1.0, ('girl is', 'fille est'))\n",
      "(1.0, ('girl', 'fille'))\n",
      "(1.0, ('france has a beautiful church', 'la france a une belle eglise'))\n",
      "(1.0, ('france has a beautiful church', 'france a une belle eglise'))\n",
      "(1.0, ('france has a beautiful', 'la france a une belle'))\n",
      "(1.0, ('france has a beautiful', 'france a une belle'))\n",
      "(1.0, ('france has a', 'la france a une'))\n",
      "(1.0, ('france has a', 'france a une'))\n",
      "(1.0, ('france has', 'la france a'))\n",
      "(1.0, ('france has', 'france a'))\n",
      "(1.0, ('france', 'la france'))\n",
      "(1.0, ('france', 'france'))\n",
      "(1.0, ('city in france', 'ville en france'))\n",
      "(1.0, ('city in', 'ville en'))\n",
      "(1.0, ('city', 'ville'))\n",
      "(1.0, ('church is in paris', 'eglise est en paris'))\n",
      "(1.0, ('church is in', 'eglise est en'))\n",
      "(1.0, ('church is beautiful', 'eglise est belle'))\n",
      "(1.0, ('church is', 'eglise est'))\n",
      "(1.0, ('church', 'eglise'))\n",
      "(1.0, ('beautiful city', 'belle ville'))\n",
      "(1.0, ('beautiful church', 'belle eglise'))\n",
      "(1.0, ('beautiful', 'belle'))\n",
      "(1.0, ('a city in france', 'une ville en france'))\n",
      "(1.0, ('a city in', 'une ville en'))\n",
      "(1.0, ('a city', 'une ville'))\n",
      "(1.0, ('a church is in paris', 'une eglise est en paris'))\n",
      "(1.0, ('a church is in', 'une eglise est en'))\n",
      "(1.0, ('a church is', 'une eglise est'))\n",
      "(1.0, ('a church', 'une eglise'))\n",
      "(1.0, ('a beautiful city', 'une belle ville'))\n",
      "(1.0, ('a beautiful church', 'une belle eglise'))\n",
      "(1.0, ('a beautiful', 'une belle'))\n",
      "(1.0, ('a', 'une'))\n",
      "(0.6666666666666666, ('the girl is', 'la fille est'))\n",
      "(0.6666666666666666, ('the girl', 'la fille'))\n",
      "(0.5, ('in', 'a'))\n",
      "(0.5, ('has', 'a'))\n",
      "(0.3333333333333333, ('girl is', 'la fille est'))\n",
      "(0.3333333333333333, ('girl', 'la fille'))\n"
     ]
    }
   ],
   "source": [
    "#This list will contain tuples of the form (phrase_translation_score,(english_phrase, foreign_phrase))\n",
    "score_to_phrase_pair=[]\n",
    "phrase_t={}\n",
    "for key,val in sorted(count_en_fr_phrase.items()):\n",
    "    #print(key,val)\n",
    "    phrase_t[key]=1.0*val/count_fr_phrase[key[1]]\n",
    "    score_to_phrase_pair.append((phrase_t[key],key))\n",
    "\n",
    "for i in sorted(score_to_phrase_pair)[::-1]:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
